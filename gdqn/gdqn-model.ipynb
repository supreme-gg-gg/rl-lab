{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Main Trigger -- _Manual Version_\n",
    "\n",
    "This is a Jupyter Notebook that is temporarily used as the main trigger for training and testing the GDQN model. Certain values, such as training period, are hardcoded for now and since the practice is not sustainable we plan to provide better alternatives soon.\n",
    "\n",
    "> Yes, we are very outdated and you need to run scripts by hand, unfortunately. If you think that's miserable, think about the respectable developer who did this hundreds of times... (crying...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym, torch\n",
    "import matplotlib.pyplot as plt\n",
    "from agent import DQNAgent\n",
    "from agent_portfolio import AgentPortfolio\n",
    "from utils.helper import plot_durations\n",
    "import utils.envs\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traing the Agent\n",
    "\n",
    "The following code trains the GDQN Agent. The period has been harcoded as 7 years and the model will automatically use the first 7 years of daily stock data for training. The rest are discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('trading-v0')\n",
    "\n",
    "num_episodes = 7 # We have 7 years of data in training and 3 years in testing\n",
    "\n",
    "agent = DQNAgent(env, device)\n",
    "\n",
    "episode_durations = agent.train_agent(num_episodes)\n",
    "\n",
    "# we can decide if we want to modularize this as well, but probably no?\n",
    "# if yes we will add it to the DQNAgent.train_agent() method\n",
    "print(\"Training Complete\")\n",
    "plot_durations(episode_durations, show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the agent\n",
    "\n",
    "To test the agent, we will use 3 years of 10 years total stock data. The start date for now is manually specified, but we can make simple changes to make it filter / process the data and start automatically for 3 years after 7 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hardcode for now the testing period\n",
    "test_env = gym.make(\"trading-v0\")\n",
    "\n",
    "test_agent = AgentPortfolio(test_env, device, \"../models/gdqn_trained.pth\", 100_000)\n",
    "\n",
    "test_agent.test_agent(3)\n",
    "\n",
    "print(\"Testing Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda venv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
