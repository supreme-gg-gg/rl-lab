{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9ip_0XlOKy_"
   },
   "outputs": [],
   "source": [
    "! pip install wandb gymnasium tqdm torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODnKME3zZ6EH"
   },
   "outputs": [],
   "source": [
    "! apt-get install -y build-essential swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ehq1EzTxZ6il"
   },
   "outputs": [],
   "source": [
    "! pip install \"gymnasium[box2d]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYKXOpu5NjQE"
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgZCUQJvZXXm"
   },
   "outputs": [],
   "source": [
    "from config import *\n",
    "from replay_buffer import *\n",
    "from networks import *\n",
    "from agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SloYvEaZOScE"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "env = gym.make(ENV_NAME, render_mode=\"human\")\n",
    "agent = DDPGAgent(env, device)\n",
    "\n",
    "if PATH_LOAD is not None:\n",
    "    print(\"loading weights\")\n",
    "    agent.load_models()\n",
    "\n",
    "states, _ = env.reset()\n",
    "done = False\n",
    "score = 0\n",
    "noise = np.zeros(agent.actions_dim)\n",
    "while not done:\n",
    "    action = agent.get_action(states, noise, evaluation=True)\n",
    "    new_states, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    score += reward\n",
    "    states = new_states\n",
    "print(f\"Inference score: {score}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dt98y_vETAIk"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTjCk83bOUKx"
   },
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "agent = DDPGAgent(env, device)\n",
    "agent.path_save = \"./\"\n",
    "agent.path_load = \"./\"\n",
    "\n",
    "config = {\n",
    "    \"learning_rate_actor\": ACTOR_LR,\n",
    "    \"learning_rate_critic\": ACTOR_LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"architecture\": \"DDPG\",\n",
    "    \"infra\": \"MacOS\",\n",
    "    \"env\": ENV_NAME\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=f\"ddpg_{ENV_NAME.lower()}\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Main training loop\n",
    "for i in tqdm(range(MAX_GAMES)):\n",
    "    start_time = time.time()\n",
    "    states, _ = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    noise = np.zeros(agent.actions_dim)\n",
    "    while not done:\n",
    "        action = agent.get_action(states, noise)\n",
    "        new_states, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "        agent.replay_buffer.push(states, action, reward, new_states, done)\n",
    "        agent.learn()\n",
    "        states = new_states\n",
    "\n",
    "    agent.replay_buffer.update_n_games()\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "    wandb.log({'Game number': agent.replay_buffer.n_games, '# Episodes': agent.replay_buffer.buffer_counter,\n",
    "            \"Average reward\": round(np.mean(scores[-10:]), 2), \\\n",
    "                    \"Time taken\": round(time.time() - start_time, 2)})\n",
    "\n",
    "    # Log Q-value estimate on a batch of states and actions from the replay buffer\n",
    "    if agent.replay_buffer.buffer_counter > agent.replay_buffer.batch_size:\n",
    "        # Sample batch for a more representative Q-value\n",
    "        batch_states, batch_actions, _, _, _ = agent.replay_buffer.sample()\n",
    "        with torch.no_grad():\n",
    "            q_values = agent.critic(torch.tensor(batch_states, dtype=torch.float32).to(device), torch.tensor(batch_actions, dtype=torch.float32).to(device)).mean().detach().item()\n",
    "        wandb.log({\"Average Q-value\": q_values})\n",
    "\n",
    "    if (i + 1) % SAVE_FREQUENCY == 0:\n",
    "        print(\"saving...\")\n",
    "        agent.save_models()\n",
    "        print(\"saved\")\n",
    "\n",
    "agent.save_models()\n",
    "\n",
    "# Create and log artifact\n",
    "artifact = wandb.Artifact(name=\"model_saved\", type=\"model\")\n",
    "artifact.add_file(\"actor.pth\")\n",
    "artifact.add_file(\"critic.pth\")\n",
    "wandb.log_artifact(artifact)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
