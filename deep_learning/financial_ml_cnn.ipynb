{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3vIFmSkeiMI"
   },
   "source": [
    "### Training Script for CNN\n",
    "\n",
    "The original Python script is adapted to a Jupyter Notebook to be trained and tested on Google Colab. The deployment of the model should not rely on this Notebook as it is inconsistent with the design of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5BK-49kX0Eo"
   },
   "outputs": [],
   "source": [
    "STOCK_NAME = \"MSFT\" # Change this before runnign\n",
    "SAVE_MODEL = False # Testing mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nksDRHFBUR7S"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnvs57_4JD0f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvyYZW9jTJui"
   },
   "source": [
    "### Custom Data Loading\n",
    "\n",
    "Since this is just built as a training trigger, we do not intend to include complicated data processing helper functions. The `get_data` function is based on a function in helper.py but has been heavily modified to **work only in this specific context**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaBJ6gTddLAC"
   },
   "outputs": [],
   "source": [
    "def get_data(stock, scale=True):\n",
    "\n",
    "    '''\n",
    "    This modified version is only meant to work\n",
    "    as a compromise for the CNN training notebook.\n",
    "    It is designed to work well with CSV formats\n",
    "    from Yahoo Finance API as well as Nasdaq\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(f\"{stock}.csv\", header=0)\n",
    "    df = df[1:].reset_index(drop=True) # drop the first row\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # This parse dates in both 2024-09-11 and 09/11/2024 formats dynamically\n",
    "    if df[\"Date\"].dtype != \"datetime64[ns]\":\n",
    "        # First, try parsing the default format (ISO 8601: YYYY-MM-DD)\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "        # If any dates failed to parse, they will be NaT, so try parsing MM/DD/YYYY format for those\n",
    "        if df['Date'].isna().any():\n",
    "            df['Date'] = df['Date'].fillna(pd.to_datetime(df['Date'], format='%m/%d/%Y', errors='coerce'))\n",
    "\n",
    "    # Handle certain csv with $ symbol before number\n",
    "    for col in df.columns:\n",
    "\n",
    "        if df[col].dtype == \"object\":\n",
    "          df[col] = df[col].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "        # If adjusted closing is available it is preferred\n",
    "        # Rename Adj Close to Close to make future references simpler\n",
    "        if col == \"Adj Close\":\n",
    "          df.drop(columns=[\"Close\"], inplace=True)\n",
    "          df.rename(columns={\"Adj Close\": \"Close\"}, inplace=True)\n",
    "\n",
    "        elif col == \"Volume\":\n",
    "          df.drop(columns=[\"Volume\"], inplace=True)\n",
    "\n",
    "        elif col == \"Date\" and df.index.name != \"Date\":\n",
    "          df.index.name = \"Date\"\n",
    "          df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "        elif col == \"Close/Last\":\n",
    "          df.rename(columns={\"Close/Last\": \"Close\"}, inplace=True)\n",
    "\n",
    "    df['Return'] = df[\"Close\"].pct_change()\n",
    "    df[\"SMA\"] = df[\"Close\"].rolling(15).mean().shift()\n",
    "    df[\"EMA\"] = df[\"Close\"].ewm(5).mean().shift()\n",
    "\n",
    "    R = df.Return\n",
    "    if scale:\n",
    "        mean = df.mean(axis=0)\n",
    "        std = df.std(axis=0)\n",
    "        df = (df - mean) / std\n",
    "    df['Return'] = R # Return is not scaled\n",
    "\n",
    "    # The first 15 rows are removed as they contain NaN values\n",
    "    # due to the computation of technical indicators\n",
    "\n",
    "    return df[15:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3gmjfHPcmgo",
    "outputId": "5b6d8fba-f8a4-45c8-d210-c73c91f57134"
   },
   "outputs": [],
   "source": [
    "# Load the stock data\n",
    "# data = pd.read_csv('AAPL_raw.csv', index_col='Date', parse_dates=True)\n",
    "# data = get_data(\"GOOG\", scale=False)\n",
    "\n",
    "data = get_data(STOCK_NAME, scale=False)\n",
    "\n",
    "# For this particular setup we don't use volumne nor return\n",
    "labels = data[\"Close\"].dropna()\n",
    "data.drop(columns=[\"Return\", \"Close\"], inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(labels.head())\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "close_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "close_scaler.fit(labels.values.reshape(-1, 1))\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "labels = scaler.fit_transform(labels.values.reshape(-1, 1))\n",
    "\n",
    "# Create the training and testing datasets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.4, train_size=0.6, shuffle=False)\n",
    "test_data, val_data, test_labels, val_labels = train_test_split(test_data, test_labels, test_size=0.5, train_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f82UY5KkRug4",
    "outputId": "fb3baeaa-1413-4abc-9f81-6ebec617d60f"
   },
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "print(val_data.shape)\n",
    "print(val_labels.shape)\n",
    "\n",
    "print(train_data[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcGBTnC-cr7B"
   },
   "outputs": [],
   "source": [
    "# Create the training and testing sequences\n",
    "def create_sequences(data, labels, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        _x = data[i:(i + seq_length)]\n",
    "        _y = labels[i + seq_length]\n",
    "        X.append(_x)\n",
    "        y.append(_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 10 # Two weeks of sequential data\n",
    "\n",
    "# train_X will be a 3D array and train_y a 2D array\n",
    "train_X, train_y = create_sequences(train_data, train_labels, seq_length)\n",
    "test_X, test_y = create_sequences(test_data, test_labels, seq_length)\n",
    "val_X, val_y = create_sequences(val_data, val_labels, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4_XuNy2Rw2e",
    "outputId": "feeb5569-756f-485b-97e1-54de624ea13e"
   },
   "outputs": [],
   "source": [
    "print(train_X[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8cRD9DDmc4Fd",
    "outputId": "546c3dc9-efd0-4619-8fb1-d3145efbf45d"
   },
   "outputs": [],
   "source": [
    "def create_model(n_features):\n",
    "\n",
    "    # Define the CNN-DNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(seq_length, n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))  # Increased number of units\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))  # Added another dense layer\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')  # Reduced learning rate\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model(5)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WcV0eeCh6D6",
    "outputId": "ac44375f-a55c-45a9-e726-ebea36c666a8"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_X, train_y, epochs=75, batch_size=32, validation_data=(val_X, val_y))  # Increased epochs\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(test_X, test_y, verbose=0)\n",
    "print('Test Loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRUWpuDmhIQD",
    "outputId": "52fe3dd0-7d43-4d0f-ee0e-135cab171c9c"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(test_X)\n",
    "\n",
    "if SAVE_MODEL: model.save(\"cnn_model.keras\")\n",
    "\n",
    "print(predictions[:5])\n",
    "print(test_y[:5])\n",
    "\n",
    "# Inverse transform the predictions to get the original scale\n",
    "# Use the 'Close' feature scaler to inverse transform the predictions\n",
    "predictions = close_scaler.inverse_transform(predictions)\n",
    "test_y = close_scaler.inverse_transform(test_y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nzwi6g3ykRTz"
   },
   "source": [
    "### To be improved:\n",
    "\n",
    "Currently, you can easily notice that the x-axis does not have the most informative label... What on Earth does _\"Days since 2021-01-01\"_ possibly mean! And honestly, we are not even sure of the date!\n",
    "\n",
    "The cause of the issue has been diagnosed and identified to be the `train_test_split` function since it returns an `numpy ndarray` from a `pandas df`, effectively getting rid of the `\"Date\"` index.\n",
    "\n",
    "> Before the script is released to final usage and integrated with the rest of the system, the problem should be addressed for consistent evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "34CM52UIc7NU",
    "outputId": "a032c048-cb88-4161-d227-bcc2a733a218"
   },
   "outputs": [],
   "source": [
    "plt.plot(test_y, label='Actual')\n",
    "plt.xlabel('Days since test period start')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.legend()\n",
    "plt.savefig('stock_price_prediction.png')\n",
    "plt.ion()\n",
    "# plt.pause(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4Ntnl1-gbEI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
